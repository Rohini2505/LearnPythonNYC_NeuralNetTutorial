{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to Keras: Examples of different model architectures and parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = pickle.load(open(\"MNIST_train_x.pkl\", 'rb'))\n",
    "train_y = pickle.load(open(\"MNIST_train_y.pkl\", 'rb'))\n",
    "test_x = pickle.load(open(\"MNIST_test_x.pkl\", 'rb'))\n",
    "test_y = pickle.load(open(\"MNIST_test_y.pkl\", 'rb'))\n",
    "train_x_short = train_x[:20000]\n",
    "train_y_short = train_y[:20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic cost (mean squared error) vs. categorical crossentropy\n",
    "- Categorical cross-entropy significantly speeds up training\n",
    "- Softmax output layers are the most appropriate for the MNIST problem since each image can only belong to one class and softmax outputs a proability distribution across the 10 classes.\n",
    "    - As the value of one output node increases, the value of one or more other output nodes must decrease\n",
    "    - This is consistent with our intuition that as we become more confident and image belongs to one class, we reduce our confidence that an image belongs to other classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 0.0943 - acc: 0.1286 - val_loss: 0.0920 - val_acc: 0.1608\n",
      "Epoch 2/10\n",
      "0s - loss: 0.0907 - acc: 0.1831 - val_loss: 0.0893 - val_acc: 0.2165\n",
      "Epoch 3/10\n",
      "0s - loss: 0.0879 - acc: 0.2344 - val_loss: 0.0868 - val_acc: 0.2627\n",
      "Epoch 4/10\n",
      "0s - loss: 0.0854 - acc: 0.2835 - val_loss: 0.0843 - val_acc: 0.3023\n",
      "Epoch 5/10\n",
      "0s - loss: 0.0828 - acc: 0.3231 - val_loss: 0.0819 - val_acc: 0.3392\n",
      "Epoch 6/10\n",
      "0s - loss: 0.0803 - acc: 0.3548 - val_loss: 0.0796 - val_acc: 0.3690\n",
      "Epoch 7/10\n",
      "0s - loss: 0.0780 - acc: 0.3823 - val_loss: 0.0775 - val_acc: 0.3977\n",
      "Epoch 8/10\n",
      "0s - loss: 0.0758 - acc: 0.4104 - val_loss: 0.0754 - val_acc: 0.4270\n",
      "Epoch 9/10\n",
      "0s - loss: 0.0738 - acc: 0.4395 - val_loss: 0.0735 - val_acc: 0.4500\n",
      "Epoch 10/10\n",
      "0s - loss: 0.0719 - acc: 0.4669 - val_loss: 0.0718 - val_acc: 0.4730\n",
      "\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 1.4947 - acc: 0.5833 - val_loss: 1.0786 - val_acc: 0.7435\n",
      "Epoch 2/10\n",
      "0s - loss: 0.8706 - acc: 0.7999 - val_loss: 0.7800 - val_acc: 0.8203\n",
      "Epoch 3/10\n",
      "0s - loss: 0.6810 - acc: 0.8446 - val_loss: 0.6485 - val_acc: 0.8448\n",
      "Epoch 4/10\n",
      "0s - loss: 0.5804 - acc: 0.8654 - val_loss: 0.5731 - val_acc: 0.8618\n",
      "Epoch 5/10\n",
      "0s - loss: 0.5177 - acc: 0.8801 - val_loss: 0.5177 - val_acc: 0.8748\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4684 - acc: 0.8926 - val_loss: 0.4810 - val_acc: 0.8820\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4326 - acc: 0.8991 - val_loss: 0.4514 - val_acc: 0.8850\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4087 - acc: 0.9014 - val_loss: 0.4298 - val_acc: 0.8898\n",
      "Epoch 9/10\n",
      "0s - loss: 0.3830 - acc: 0.9075 - val_loss: 0.4139 - val_acc: 0.8935\n",
      "Epoch 10/10\n",
      "0s - loss: 0.3622 - acc: 0.9134 - val_loss: 0.3927 - val_acc: 0.9002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x113f0a630>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Softmax output layer, mse\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd, loss='mse', metrics=['accuracy'])\n",
    "model.fit(train_x_short, train_y_short, batch_size=128, nb_epoch=10, validation_split=0.2, verbose=2)\n",
    "print()\n",
    "\n",
    "# Softmax output layer, categorical crossentropy\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_x_short, train_y_short, batch_size=128, nb_epoch=10, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing the batch_size tends to increase the amount learnt per epoch, but also increases time to complete an epoch\n",
    "- In the experiments below total time to reach a comparable accuracy level was broadly similar\n",
    "- Reducing batch size from 32 to 16 appeared to hurt performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 1.5686 - acc: 0.5379 - val_loss: 1.1132 - val_acc: 0.7535\n",
      "Epoch 2/10\n",
      "0s - loss: 0.9154 - acc: 0.7976 - val_loss: 0.8008 - val_acc: 0.8227\n",
      "Epoch 3/10\n",
      "0s - loss: 0.7039 - acc: 0.8436 - val_loss: 0.6599 - val_acc: 0.8562\n",
      "Epoch 4/10\n",
      "0s - loss: 0.5978 - acc: 0.8657 - val_loss: 0.5771 - val_acc: 0.8685\n",
      "Epoch 5/10\n",
      "0s - loss: 0.5285 - acc: 0.8774 - val_loss: 0.5265 - val_acc: 0.8758\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4787 - acc: 0.8893 - val_loss: 0.4821 - val_acc: 0.8858\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4441 - acc: 0.8946 - val_loss: 0.4598 - val_acc: 0.8878\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4153 - acc: 0.9023 - val_loss: 0.4347 - val_acc: 0.8898\n",
      "Epoch 9/10\n",
      "0s - loss: 0.3910 - acc: 0.9059 - val_loss: 0.4121 - val_acc: 0.8940\n",
      "Epoch 10/10\n",
      "0s - loss: 0.3705 - acc: 0.9123 - val_loss: 0.3990 - val_acc: 0.8978\n",
      "Model took  6.8437159061431885 seconds to complete\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_x_short, train_y_short, batch_size=128, nb_epoch=10, validation_split=0.2, verbose=2)\n",
    "end = time.time()\n",
    "print(\"Model took  {} seconds to complete\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/7\n",
      "0s - loss: 1.2380 - acc: 0.6774 - val_loss: 0.8062 - val_acc: 0.8157\n",
      "Epoch 2/7\n",
      "0s - loss: 0.6709 - acc: 0.8466 - val_loss: 0.5969 - val_acc: 0.8572\n",
      "Epoch 3/7\n",
      "0s - loss: 0.5269 - acc: 0.8778 - val_loss: 0.5000 - val_acc: 0.8750\n",
      "Epoch 4/7\n",
      "1s - loss: 0.4545 - acc: 0.8897 - val_loss: 0.4575 - val_acc: 0.8875\n",
      "Epoch 5/7\n",
      "0s - loss: 0.4111 - acc: 0.8992 - val_loss: 0.4173 - val_acc: 0.8915\n",
      "Epoch 6/7\n",
      "0s - loss: 0.3734 - acc: 0.9071 - val_loss: 0.3874 - val_acc: 0.8988\n",
      "Epoch 7/7\n",
      "0s - loss: 0.3471 - acc: 0.9130 - val_loss: 0.3633 - val_acc: 0.9022\n",
      "Model took  6.3559348583221436 seconds to complete\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_x_short, train_y_short, batch_size=64, nb_epoch=7, validation_split=0.2, verbose=2)\n",
    "end = time.time()\n",
    "print(\"Model took  {} seconds to complete\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/6\n",
      "0s - loss: 1.0527 - acc: 0.7224 - val_loss: 0.6616 - val_acc: 0.8365\n",
      "Epoch 2/6\n",
      "0s - loss: 0.5545 - acc: 0.8621 - val_loss: 0.5231 - val_acc: 0.8645\n",
      "Epoch 3/6\n",
      "0s - loss: 0.4575 - acc: 0.8848 - val_loss: 0.4338 - val_acc: 0.8838\n",
      "Epoch 4/6\n",
      "0s - loss: 0.3986 - acc: 0.8976 - val_loss: 0.3936 - val_acc: 0.8940\n",
      "Epoch 5/6\n",
      "0s - loss: 0.3635 - acc: 0.9054 - val_loss: 0.3775 - val_acc: 0.8990\n",
      "Epoch 6/6\n",
      "0s - loss: 0.3488 - acc: 0.9076 - val_loss: 0.3581 - val_acc: 0.9005\n",
      "Model took  5.353495836257935 seconds to complete\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_x_short, train_y_short, batch_size=32, nb_epoch=6, validation_split=0.2, verbose=2)\n",
    "end = time.time()\n",
    "print(\"Model took  {} seconds to complete\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/6\n",
      "1s - loss: 0.9557 - acc: 0.7491 - val_loss: 0.6549 - val_acc: 0.8355\n",
      "Epoch 2/6\n",
      "1s - loss: 0.5316 - acc: 0.8621 - val_loss: 0.4923 - val_acc: 0.8618\n",
      "Epoch 3/6\n",
      "1s - loss: 0.4494 - acc: 0.8814 - val_loss: 0.4298 - val_acc: 0.8835\n",
      "Epoch 4/6\n",
      "1s - loss: 0.4101 - acc: 0.8922 - val_loss: 0.3863 - val_acc: 0.8972\n",
      "Epoch 5/6\n",
      "1s - loss: 0.3795 - acc: 0.8991 - val_loss: 0.4022 - val_acc: 0.8922\n",
      "Epoch 6/6\n",
      "1s - loss: 0.3677 - acc: 0.8979 - val_loss: 0.3580 - val_acc: 0.8965\n",
      "Model took  6.903819799423218 seconds to complete\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_x_short, train_y_short, batch_size=16, nb_epoch=6, validation_split=0.2, verbose=2)\n",
    "end = time.time()\n",
    "print(\"Model took  {} seconds to complete\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu + softmax\n",
    "- Needs a low learning rate for the network to learn anything\n",
    "- Performs worse than a sigmoid hidden layer for shallow networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 10.8614 - acc: 0.3217 - val_loss: 10.5951 - val_acc: 0.3382\n",
      "Epoch 2/10\n",
      "0s - loss: 9.7185 - acc: 0.3927 - val_loss: 9.5325 - val_acc: 0.4035\n",
      "Epoch 3/10\n",
      "0s - loss: 8.8254 - acc: 0.4496 - val_loss: 8.8532 - val_acc: 0.4465\n",
      "Epoch 4/10\n",
      "0s - loss: 8.7444 - acc: 0.4550 - val_loss: 8.8393 - val_acc: 0.4495\n",
      "Epoch 5/10\n",
      "0s - loss: 8.0795 - acc: 0.4961 - val_loss: 7.4797 - val_acc: 0.5323\n",
      "Epoch 6/10\n",
      "0s - loss: 7.2350 - acc: 0.5482 - val_loss: 7.4038 - val_acc: 0.5373\n",
      "Epoch 7/10\n",
      "0s - loss: 6.7769 - acc: 0.5744 - val_loss: 6.2869 - val_acc: 0.6025\n",
      "Epoch 8/10\n",
      "0s - loss: 5.8232 - acc: 0.6324 - val_loss: 6.0675 - val_acc: 0.6155\n",
      "Epoch 9/10\n",
      "0s - loss: 5.3256 - acc: 0.6641 - val_loss: 5.6016 - val_acc: 0.6480\n",
      "Epoch 10/10\n",
      "0s - loss: 4.8013 - acc: 0.6951 - val_loss: 4.9422 - val_acc: 0.6850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x118bd9e48>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=784))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.001)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_x_short, train_y_short, batch_size=32, nb_epoch=10, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 1.0783 - acc: 0.7277 - val_loss: 0.7008 - val_acc: 0.8327\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5685 - acc: 0.8558 - val_loss: 0.5170 - val_acc: 0.8698\n",
      "Epoch 3/10\n",
      "0s - loss: 0.4600 - acc: 0.8815 - val_loss: 0.4459 - val_acc: 0.8838\n",
      "Epoch 4/10\n",
      "0s - loss: 0.3988 - acc: 0.8950 - val_loss: 0.4047 - val_acc: 0.8962\n",
      "Epoch 5/10\n",
      "0s - loss: 0.3652 - acc: 0.9046 - val_loss: 0.3760 - val_acc: 0.9058\n",
      "Epoch 6/10\n",
      "0s - loss: 0.3436 - acc: 0.9065 - val_loss: 0.3485 - val_acc: 0.9067\n",
      "Epoch 7/10\n",
      "0s - loss: 0.3132 - acc: 0.9136 - val_loss: 0.3331 - val_acc: 0.9117\n",
      "Epoch 8/10\n",
      "0s - loss: 0.3031 - acc: 0.9187 - val_loss: 0.3267 - val_acc: 0.9107\n",
      "Epoch 9/10\n",
      "0s - loss: 0.2942 - acc: 0.9194 - val_loss: 0.3043 - val_acc: 0.9165\n",
      "Epoch 10/10\n",
      "0s - loss: 0.2837 - acc: 0.9251 - val_loss: 0.3081 - val_acc: 0.9187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x117a75198>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(128, input_dim=784))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.add(Dense(10))\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01)\n",
    "model2.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model2.fit(train_x_short, train_y_short, batch_size=32, nb_epoch=10, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu really comes into its own for deep networks\n",
    "- Deeper network tend to perform better than shallow networks for complex tasks\n",
    "- But they are hard to train. Relu's make it easier for deep networks to learn because their gradients don't saturate for postive inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "1s - loss: 8.2822 - acc: 0.4715 - val_loss: 7.4159 - val_acc: 0.5308\n",
      "Epoch 2/10\n",
      "2s - loss: 6.0692 - acc: 0.6049 - val_loss: 4.7384 - val_acc: 0.6823\n",
      "Epoch 3/10\n",
      "2s - loss: 3.8278 - acc: 0.7366 - val_loss: 2.1670 - val_acc: 0.8093\n",
      "Epoch 4/10\n",
      "1s - loss: 0.9286 - acc: 0.9003 - val_loss: 0.9505 - val_acc: 0.8902\n",
      "Epoch 5/10\n",
      "2s - loss: 0.4477 - acc: 0.9386 - val_loss: 0.5667 - val_acc: 0.9120\n",
      "Epoch 6/10\n",
      "1s - loss: 0.2416 - acc: 0.9581 - val_loss: 0.4728 - val_acc: 0.9240\n",
      "Epoch 7/10\n",
      "1s - loss: 0.1488 - acc: 0.9739 - val_loss: 0.4283 - val_acc: 0.9283\n",
      "Epoch 8/10\n",
      "1s - loss: 0.1016 - acc: 0.9823 - val_loss: 0.4186 - val_acc: 0.9317\n",
      "Epoch 9/10\n",
      "1s - loss: 0.0720 - acc: 0.9909 - val_loss: 0.3961 - val_acc: 0.9325\n",
      "Epoch 10/10\n",
      "1s - loss: 0.0568 - acc: 0.9945 - val_loss: 0.3994 - val_acc: 0.9367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x113d3beb8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(512, input_dim=784))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Dense(256))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Dense(128))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Dense(64))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Dense(10))\n",
    "model3.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.001)\n",
    "model3.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.fit(train_x_short, train_y_short, batch_size=32, nb_epoch=10, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "3s - loss: 2.3056 - acc: 0.1231 - val_loss: 2.2900 - val_acc: 0.1182\n",
      "Epoch 2/10\n",
      "5s - loss: 2.2853 - acc: 0.1509 - val_loss: 2.2806 - val_acc: 0.1182\n",
      "Epoch 3/10\n",
      "4s - loss: 2.2729 - acc: 0.1845 - val_loss: 2.2647 - val_acc: 0.2125\n",
      "Epoch 4/10\n",
      "3s - loss: 2.2556 - acc: 0.2496 - val_loss: 2.2444 - val_acc: 0.3855\n",
      "Epoch 5/10\n",
      "4s - loss: 2.2294 - acc: 0.3211 - val_loss: 2.2120 - val_acc: 0.3033\n",
      "Epoch 6/10\n",
      "4s - loss: 2.1866 - acc: 0.3882 - val_loss: 2.1569 - val_acc: 0.4338\n",
      "Epoch 7/10\n",
      "3s - loss: 2.1122 - acc: 0.4689 - val_loss: 2.0596 - val_acc: 0.4693\n",
      "Epoch 8/10\n",
      "3s - loss: 1.9872 - acc: 0.4995 - val_loss: 1.9100 - val_acc: 0.5230\n",
      "Epoch 9/10\n",
      "3s - loss: 1.8193 - acc: 0.5250 - val_loss: 1.7310 - val_acc: 0.5182\n",
      "Epoch 10/10\n",
      "3s - loss: 1.6228 - acc: 0.5627 - val_loss: 1.5260 - val_acc: 0.5657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x118234a90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(512, input_dim=784))\n",
    "model3.add(Activation('sigmoid'))\n",
    "model3.add(Dense(256))\n",
    "model3.add(Activation('sigmoid'))\n",
    "model3.add(Dense(128))\n",
    "model3.add(Activation('sigmoid'))\n",
    "model3.add(Dense(64))\n",
    "model3.add(Activation('sigmoid'))\n",
    "model3.add(Dense(10))\n",
    "model3.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01)\n",
    "model3.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.fit(train_x_short, train_y_short, batch_size=32, nb_epoch=10, validation_split=0.2, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
